{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Task_2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8uG0dqjENnH"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.sparse as sp\n",
        "import time"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTJbbRhxVORI",
        "outputId": "ac0d9e1a-f209-479c-bed0-a6fe980d9030"
      },
      "source": [
        "!gdown --id 1PnTfrm4c5VSLih-dKtV9j5tVyVeDhi5b\n",
        "!head -n 2000000 /content/combined_data_1.txt > data.txt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1PnTfrm4c5VSLih-dKtV9j5tVyVeDhi5b\n",
            "To: /content/combined_data_1.txt\n",
            "100% 495M/495M [00:04<00:00, 113MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MkbCDO4SbJg"
      },
      "source": [
        "df = pd.read_csv('data.txt', sep=',', header=0, names=[\"CustomerID\", \"Rating\", \"Date\"])\n",
        "df_null = pd.DataFrame(pd.isnull(df['Date']))\n",
        "df_movies = df\n",
        "movies_ids = df_movies['CustomerID'].copy().to_numpy()\n",
        "movie_loc = df_null[df_null['Date'] == True]\n",
        "movie_loc = np.append(movie_loc, len(df_null))\n",
        "for i in range(len(movie_loc) - 1):\n",
        "    movies_ids[movie_loc[i] + 1: movie_loc[i + 1]] = i + 1\n",
        "df_movies.insert(0, 'MovieId', movies_ids)\n",
        "df_movies = df_movies[~pd.isnull(df_movies['Date'])]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnqyz-nxEs5n"
      },
      "source": [
        "pd_null = pd.isna(df[\"Date\"]).to_numpy()\n",
        "df_with_movies = df\n",
        "movie_ids = df[\"CustomerID\"].copy().to_numpy()\n",
        "movie_pos = np.where(pd_null == True)[0]\n",
        "movie_pos = np.append(movie_pos, len(pd_null))\n",
        "for i in range(len(movie_pos) - 1):\n",
        "  movie_ids[movie_pos[i] + 1 : movie_pos[i + 1]] = i + 1\n",
        "df_with_movies.insert(0, \"ID\", movie_ids)\n",
        "df_with_movies = df_with_movies[~pd.isna(df_with_movies[\"Date\"])]\n",
        "df_with_movies = df_with_movies.sample(frac=1).reset_index(drop=True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ho85x9YZWRFx"
      },
      "source": [
        "customer_TID = {int(customer_id):i for i, customer_id in enumerate(df_with_movies[\"CustomerID\"].unique())}\n",
        "movie_TID = {movie_id:(i + len(customer_TID)) for i, movie_id in enumerate(df_with_movies[\"ID\"].unique())}\n",
        "\n",
        "customers = df_with_movies[\"CustomerID\"].apply(lambda x: customer_TID[int(x)]).to_numpy().astype(int)\n",
        "movies = df_with_movies[\"ID\"].apply(lambda x: movie_TID[x]).to_numpy()\n",
        "\n",
        "customer_cnt = df_with_movies[\"CustomerID\"].nunique()\n",
        "movie_cnt = df_with_movies[\"ID\"].nunique()\n",
        "rating_cnt = df_with_movies.shape[0]\n",
        "\n",
        "col_id = np.dstack((customers, movies)).flatten()\n",
        "row_id = np.repeat(np.arange(rating_cnt), 2)\n",
        "\n",
        "df = np.ones(rating_cnt * 2, dtype=int)\n",
        "hot_matrix = sp.csr_matrix((df, (row_id, col_id)), shape=(rating_cnt, customer_cnt + movie_cnt))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fau2hwzvVWg"
      },
      "source": [
        "def rmse(gt, prediction):\n",
        "  return np.sqrt(sum((gt - prediction) ** 2) / len(gt))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0X1zQ2UKXREo"
      },
      "source": [
        "def generate_cross_validation_ids(x, y, sample_cnt=5):\n",
        "    ids = np.arange(x.shape[0])\n",
        "    np.random.shuffle(ids)\n",
        "\n",
        "    sample_size = x.shape[0] // sample_cnt\n",
        "    for i in range(sample_cnt):\n",
        "        test = np.zeros(x.shape[0], dtype=bool)\n",
        "        train = np.zeros(x.shape[0], dtype=bool)\n",
        "        test[ids[i * sample_size:(i + 1) * sample_size]] = True\n",
        "        train[ids[:i * sample_size]] = True\n",
        "        train[ids[(i + 1) * sample_size:]] = True\n",
        "        yield x[train], y[train], x[test], y[test]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZlTyuiibic1"
      },
      "source": [
        "def generate_batches(x, y, batch_size):\n",
        "        ids = np.arange(x.shape[0])\n",
        "        np.random.shuffle(ids)\n",
        "        for i in range(0, x.shape[0], batch_size):\n",
        "            batch_ids = ids[i:min(start + batch_size, x.shape[0])]\n",
        "            yield x[batch_ids], y[batch_ids]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDVRsAJXxhB-"
      },
      "source": [
        "class factorization_machine(object):\n",
        "    def __init__(self):\n",
        "      self.k = 3\n",
        "      self.W0 = 0\n",
        "      self.W = None\n",
        "      self.V = None\n",
        "      self.XV = None\n",
        "      self.X_squared = None\n",
        "      self.start_lr = 0.1\n",
        "      self.lr = self.start_lr\n",
        "    \n",
        "    def predict(self, X):\n",
        "      self.XV = X @ self.V\n",
        "      self.X_squared = X.power(2)\n",
        "      return self.W0 + X @ self.W + np.sum(self.XV ** 2 - (self.X_squared @ self.V ** 2), axis=1, keepdims=True) / 2\n",
        "\n",
        "    def get_batches(self, dataset, batch_size):\n",
        "        X, Y = dataset\n",
        "        n_samples = X.shape[0]\n",
        "\n",
        "        ids = np.arange(n_samples)\n",
        "        np.random.shuffle(ids)\n",
        "\n",
        "        for start in range(0, n_samples, batch_size):\n",
        "            end = min(start + batch_size, n_samples)\n",
        "            batch_id = ids[start:end]\n",
        "\n",
        "            yield X[batch_id], Y[batch_id]\n",
        "\n",
        "    def train(self, X, y, epoch_count=1, batch_size=512):\n",
        "      self.W = np.random.rand(X.shape[1], 1)\n",
        "      self.V = np.random.rand(X.shape[1], self.k)\n",
        "      for epoch_num in range(epoch_count):\n",
        "        for x_batch, y_batch in self.get_batches((X, y), batch_size):\n",
        "            self.lr = self.start_lr / np.sqrt(epoch_num + 1)\n",
        "            predictions = self.predict(x_batch)\n",
        "            dLoss = 2 * np.subtract(predictions, y_batch.reshape(-1, 1)) / len(y_batch)\n",
        "            self.W0 -= np.multiply(self.lr, np.sum(dLoss))\n",
        "            self.W -= np.multiply(self.lr, x_batch.transpose() @ dLoss)\n",
        "            np.multiply(self.lr, dLoss, out=dLoss)\n",
        "            \n",
        "            for f in range(self.k):\n",
        "                dV = x_batch.multiply(self.XV[:, f].reshape(-1, 1))\n",
        "                dV -= self.X_squared.multiply(self.V[:, f])\n",
        "                self.V[:, f] -= dLoss.reshape(-1) @ dV"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HANRos2kmp87"
      },
      "source": [
        "train_time = []\n",
        "train_rmse = []\n",
        "test_rmse = []\n",
        "fm = factorization_machine()\n",
        "for x_train, y_train, x_test, y_test in generate_cross_validation_ids(hot_matrix, df_with_movies[\"Rating\"].to_numpy(), 5):\n",
        "    start = time.time()\n",
        "    fm.train(x_train, y_train)\n",
        "    stop = time.time()\n",
        "    train_time.append((stop - start) / 60)\n",
        "    predictions_train = fm.predict(x_train).reshape(-1)\n",
        "    predictions_test = fm.predict(x_test).reshape(-1)\n",
        "    train_rmse.append(rmse(y_train, predictions_train))\n",
        "    test_rmse.append(rmse(y_test, predictions_test))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "XwD3fsjQo0wX",
        "outputId": "2348d2dc-a5d9-4f3a-f9cc-89341fcafb27"
      },
      "source": [
        "result = pd.DataFrame({\"train_RMSE\": train_rmse, \"test_RMSE\": test_rmse, \"Time\"\u001c: train_time}).T\n",
        "result"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>train_RMSE</th>\n",
              "      <td>1.078224</td>\n",
              "      <td>1.077928</td>\n",
              "      <td>1.077464</td>\n",
              "      <td>1.079928</td>\n",
              "      <td>1.078557</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>test_RMSE</th>\n",
              "      <td>1.079226</td>\n",
              "      <td>1.078848</td>\n",
              "      <td>1.079831</td>\n",
              "      <td>1.079467</td>\n",
              "      <td>1.079136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Time</th>\n",
              "      <td>0.658628</td>\n",
              "      <td>0.659226</td>\n",
              "      <td>0.626631</td>\n",
              "      <td>0.644580</td>\n",
              "      <td>0.661871</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   0         1         2         3         4\n",
              "train_RMSE  1.078224  1.077928  1.077464  1.079928  1.078557\n",
              "test_RMSE   1.079226  1.078848  1.079831  1.079467  1.079136\n",
              "Time        0.658628  0.659226  0.626631  0.644580  0.661871"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    }
  ]
}